# Uteki.open Replatform Proposal

**Status**: Draft
**Created**: 2026-01-26
**Author**: System Architect
**Type**: Major Replatform & Refactor

---

## Executive Summary

Transform `uchu_trade` (legacy quantitative trading system) into `uteki.open` - a modern, open-source, personal quantitative trading platform with:

- **Domain-Driven Architecture** - Clean separation of concerns across 7 core domains
- **Modern Tech Stack** - PostgreSQL, ClickHouse, Qdrant, Poetry, Ruff
- **Out-of-the-Box Experience** - One-command local deployment for individual users
- **Unified Agent Framework** - Consolidate 5+ disparate agent systems into one coherent architecture
- **Production-Ready Tooling** - Pre-commit hooks, type checking, automated testing

**Target Users**: Individual quantitative traders who want a professional-grade, self-hosted trading system without enterprise complexity.

---

## Background & Context

### Current State: uchu_trade

```
Legacy System Snapshot:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 873 Python files
â€¢ 176MB SQLite database (production data)
â€¢ 5+ different Agent implementations (buffett_agent, mongo_buffet_agent,
  trading_agent, research_agent, news_agent)
â€¢ 30+ controller modules
â€¢ Mixed dependency management (Conda + pip)
â€¢ SQLAlchemy 1.4.51 (pre-2.0 migration)
â€¢ Monolithic architecture with unclear boundaries
```

### Pain Points

1. **Architectural Debt**
   - No clear separation between domains
   - Agent systems overlap in functionality
   - Controllers directly access database models
   - Difficult to test individual components

2. **Operational Complexity**
   - Conda + pip dependency conflicts
   - 265 dependencies in environment.yml
   - No Docker support for easy deployment
   - Manual database migrations

3. **Scalability Issues**
   - SQLite limits concurrent writes
   - No time-series optimization for kline data
   - No vector search for semantic queries
   - Growing technical debt

4. **User Experience**
   - Not designed for external users
   - No onboarding flow
   - Manual configuration required
   - No built-in documentation

---

## Goals

### Primary Goals

1. **ğŸ—ï¸ Modern Architecture**
   - Domain-Driven Design (DDD) with 7 core domains
   - Clean separation: API â†’ Service â†’ Repository â†’ Models
   - Hexagonal architecture for testability

2. **ğŸ“¦ Out-of-the-Box Local Deployment**
   - Clone repo â†’ Configure keys â†’ Start trading
   - Docker Compose for one-command startup
   - Alternative: Poetry + local installation
   - Automatic database initialization

3. **ğŸ§  Unified Agent Framework**
   - Single `BaseAgent` abstraction
   - Pluggable Tool system
   - Shared Memory management (Qdrant-backed)
   - Consolidate 5 agent systems into one coherent design

4. **ğŸ’¾ Multi-Database Architecture**
   - PostgreSQL: Transactional data (orders, positions, config)
   - ClickHouse: Analytics & time-series (klines, backtest logs)
   - Qdrant: Vector search (strategy similarity, RAG)
   - Redis: Caching & real-time state

5. **ğŸ› ï¸ Production-Grade Tooling**
   - Poetry for dependency management
   - Ruff for linting + formatting (100x faster than Black)
   - MyPy for type safety
   - Pre-commit hooks
   - Pytest with 80%+ coverage

6. **ğŸ¨ Four Core Pages**
   - `/admin` - API keys, model config, usage monitoring
   - `/admin` - System configuration + trading dashboard (merged for better UX)
   - `/evaluate` - Agent evaluation, A/B testing, agent chat interface

### Secondary Goals

7. **ğŸ“Š Enhanced Analytics**
   - ClickHouse-powered fast queries (20-60x faster than PostgreSQL)
   - Historical data compression (90% space savings)
   - Real-time dashboards

8. **ğŸ” Semantic Search**
   - Strategy similarity search via embeddings
   - News article clustering
   - Agent memory retrieval (RAG)

9. **ğŸ“š Comprehensive Documentation**
   - Quick Start guide (5 minutes to first backtest)
   - Cookbook with real-world examples
   - Interactive tutorials
   - API reference (auto-generated)

---

## Non-Goals

### What We're NOT Doing

1. **âŒ SaaS / Cloud Deployment**
   - This is a self-hosted, local-first tool
   - No cloud infrastructure, no multi-tenancy (yet)
   - Users run it on their own machines

2. **âŒ Strategy Marketplace (MVP)**
   - No strategy sharing/selling in initial release
   - Architecture will support future extension
   - Focus on personal use first

3. **âŒ Multi-User Authentication (Initially)**
   - Single-user mode + Profile switching
   - Can add multi-user later if needed

4. **âŒ Mobile App**
   - Web-first responsive design only
   - No native iOS/Android apps

5. **âŒ Blockchain/DeFi Integration**
   - Focus on CEX (OKX, Binance) only
   - DEX integration is out of scope

---

## Proposal Overview

### Core Domains (Domain-Driven Design)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Uteki.open Domain Map                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. admin/          - API keys, model config, system settings
2. trading/        - Orders, positions, account management
3. strategy/       - Strategy engine, atoms, backtest, scheduler
4. agent/          - Unified agent framework, tools, memory
5. evaluation/     - Metrics, A/B testing, benchmarks, reports
6. dashboard/      - Trading history, performance visualization

Each domain contains:
â”œâ”€â”€ models.py      - SQLAlchemy models
â”œâ”€â”€ schemas.py     - Pydantic request/response schemas
â”œâ”€â”€ repository.py  - Data access layer
â”œâ”€â”€ service.py     - Business logic
â”œâ”€â”€ api.py         - FastAPI routes
â””â”€â”€ use_cases/     - Specific business operations
```

### Technology Stack

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Layer              | Current          | New              | Rationale
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Dependency Mgmt    | Conda + pip      | Poetry           | Standard, lockfile, faster
ORM                | SQLAlchemy 1.4   | SQLAlchemy 2.0   | Modern API, async support
Primary DB         | SQLite           | PostgreSQL 17    | ACID, concurrency, JSON
Analytics DB       | -                | ClickHouse       | 20-60x faster queries
Vector DB          | -                | Qdrant           | Semantic search, RAG
Cache              | -                | Redis 7          | Session, real-time state
Linter/Formatter   | -                | Ruff             | 100x faster than Black
Type Checker       | -                | MyPy (strict)    | Catch bugs early
Testing            | Manual           | Pytest + Coverage| 80%+ coverage target
API Framework      | FastAPI 0.110    | FastAPI 0.115    | Latest features
Python Version     | 3.10.9           | 3.10+            | Compatible, modern
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Deployment Model

**Hybrid Approach** (supports both):

```bash
# Option 1: Docker Compose (Recommended for new users)
git clone https://github.com/yourusername/uteki.open
cd uteki.open
cp .env.example .env  # Configure API keys
docker compose up     # Start all services
# â†’ http://localhost:3000

# Option 2: Local Development (For developers)
git clone https://github.com/yourusername/uteki.open
cd uteki.open
make install          # Poetry + npm install
make dev              # Start backend + frontend
# â†’ http://localhost:3000
```

**Smart Setup Script**:
```bash
./scripts/setup.sh
# Detects environment:
# - Has Docker? â†’ Offer Docker Compose
# - Has Python 3.10+? â†’ Offer local install
# - Let user choose
```

---

## Technical Architecture

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (React 18)                     â”‚
â”‚                   /admin /evaluate                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Application                        â”‚
â”‚                     (Python 3.10+)                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          API Layer (FastAPI Routers)               â”‚    â”‚
â”‚  â”‚  /api/v1/admin  /trading  /strategy  /agent ...    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Domain Services                       â”‚    â”‚
â”‚  â”‚  AdminService | TradingService | StrategyService   â”‚    â”‚
â”‚  â”‚  AgentService | EvaluationService | ...            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            Repository Layer                        â”‚    â”‚
â”‚  â”‚  Data access abstraction (SQLAlchemy)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚   â”‚ ClickHouse   â”‚   â”‚    Qdrant      â”‚
â”‚              â”‚   â”‚              â”‚   â”‚                â”‚
â”‚ â€¢ Orders     â”‚   â”‚ â€¢ K-lines    â”‚   â”‚ â€¢ Strategy     â”‚
â”‚ â€¢ Positions  â”‚   â”‚ â€¢ Backtest   â”‚   â”‚   embeddings   â”‚
â”‚ â€¢ Config     â”‚   â”‚   logs       â”‚   â”‚ â€¢ News vectors â”‚
â”‚ â€¢ Users      â”‚   â”‚ â€¢ Analytics  â”‚   â”‚ â€¢ Agent memory â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Design Philosophy

**Data Classification**:

```
Hot Data (PostgreSQL)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Active orders & positions (< 30 days)
â€¢ User configurations
â€¢ API keys (encrypted)
â€¢ Strategy instances
â€¢ Real-time account state
â€¢ Agent tasks (pending/running)

â†’ Optimized for: ACID transactions, concurrent writes, data integrity

Cold Data (ClickHouse)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Historical K-line data (years of data)
â€¢ Completed backtest records
â€¢ Execution logs (millions of rows)
â€¢ Performance metrics time-series
â€¢ Archived orders/positions (> 30 days)

â†’ Optimized for: Fast aggregations, compression, time-series queries

Vector Data (Qdrant)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Strategy embeddings (semantic similarity)
â€¢ News article vectors (clustering)
â€¢ Agent conversation history (RAG)
â€¢ Market analysis summaries

â†’ Optimized for: Vector similarity search, hybrid queries
```

### Agent Framework Architecture

**Unified Design** (consolidates 5 legacy systems):

```python
# Abstract base class
class BaseAgent:
    """All agents inherit from this"""

    def __init__(
        self,
        name: str,
        llm: BaseLLM,  # OpenAI/Claude/Local
        tools: list[Tool],
        memory: AgentMemory,  # Qdrant-backed
    ):
        ...

    async def execute(self, task: AgentTask) -> AgentResult:
        """Main execution loop"""
        # 1. Plan - break down task
        # 2. Execute - use tools
        # 3. Reflect - evaluate result
        # 4. Memory - store in Qdrant
        ...

# Specific implementations
class TradingAgent(BaseAgent):
    """Handles market analysis and trade execution"""
    tools = [
        MarketDataTool(),
        TechnicalIndicatorTool(),
        OrderPlacementTool(),
    ]

class ResearchAgent(BaseAgent):
    """Conducts market research"""
    tools = [
        NewsSearchTool(),
        SentimentAnalysisTool(),
        CompanyFilingTool(),
    ]

class EvaluationAgent(BaseAgent):
    """Evaluates strategy and agent performance"""
    tools = [
        BacktestTool(),
        StatisticalAnalysisTool(),
        ReportGeneratorTool(),
    ]
```

**Tool System**:

```python
class Tool:
    """Abstract tool interface"""

    name: str
    description: str
    parameters: dict  # JSON Schema

    async def execute(self, **kwargs) -> ToolResult:
        """Execute tool logic"""
        raise NotImplementedError

# Example: Market Data Tool
class MarketDataTool(Tool):
    name = "get_market_data"
    description = "Fetch real-time market data for a symbol"
    parameters = {
        "symbol": {"type": "string"},
        "interval": {"type": "string", "enum": ["1m", "5m", "1h"]},
        "limit": {"type": "integer"},
    }

    async def execute(
        self,
        symbol: str,
        interval: str,
        limit: int = 100,
    ) -> ToolResult:
        # Fetch from exchange API
        data = await exchange.get_klines(symbol, interval, limit)
        return ToolResult(success=True, data=data)
```

---

## Key Design Decisions

### 1. Why Poetry over PDM/uv?

```
Decision: Poetry
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rationale:
â€¢ Most mature (7 years, 27k+ stars)
â€¢ Best IDE integration (PyCharm, VSCode)
â€¢ Largest community â†’ easier troubleshooting
â€¢ Stable API, proven at scale
â€¢ Easy migration path to uv later (pyproject.toml compatible)

Trade-offs:
â€¢ Slower than uv (acceptable for this use case)
â€¢ Dependency resolution can be conservative

Alternatives Considered:
â€¢ PDM - Good, but smaller community
â€¢ uv - Too new (2024), prefer stability
```

### 2. Why PostgreSQL over SQLite?

```
Decision: PostgreSQL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rationale:
â€¢ Concurrent writes (multiple agents writing simultaneously)
â€¢ Better data integrity (ACID guarantees)
â€¢ JSON/JSONB support (flexible schema)
â€¢ Room to grow (SQLite limits at ~100GB)
â€¢ Industry standard for this architecture

Local Deployment:
â€¢ Docker Compose handles PostgreSQL automatically
â€¢ Provide SQLiteâ†’PostgreSQL migration script
â€¢ Zero manual setup for users

Alternatives Considered:
â€¢ SQLite - Current choice, but hitting limits
â€¢ MySQL - Less modern than PostgreSQL
```

### 3. Why ClickHouse for Analytics?

```
Decision: ClickHouse
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rationale:
â€¢ 20-60x faster queries for time-series data
â€¢ 90% data compression (save disk space)
â€¢ Columnar storage perfect for analytics
â€¢ Single-server mode (no cluster needed)
â€¢ Mature, battle-tested at scale

Use Cases:
â€¢ K-line historical data (millions of rows)
â€¢ Backtest result analysis
â€¢ Performance metrics aggregation
â€¢ Log analytics

Alternatives Considered:
â€¢ TimescaleDB - PostgreSQL extension, good but slower
â€¢ DuckDB - Fast, but newer, less proven
â€¢ Keep in PostgreSQL - Too slow for large datasets
```

### 4. Why Qdrant for Vector Search?

```
Decision: Qdrant
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rationale:
â€¢ Rust-based, high performance
â€¢ Docker single-container deployment
â€¢ Excellent Python SDK
â€¢ Hybrid search (vector + metadata filters)
â€¢ Open source, active development

Use Cases:
â€¢ Strategy similarity search
â€¢ News article clustering
â€¢ Agent memory (RAG)
â€¢ Semantic search in trading history

Alternatives Considered:
â€¢ ChromaDB - Simpler, but less performant
â€¢ Milvus - Enterprise-grade, too complex for personal use
â€¢ pgvector - PostgreSQL extension, limited features
```

### 5. Single-User vs Multi-User?

```
Decision: Single-User + Profile Switching
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Rationale:
â€¢ Aligns with "personal tool" vision
â€¢ Simpler architecture (no auth/permissions initially)
â€¢ Profile switching enables:
  - Production trading profile
  - Demo/testnet profile
  - Backtesting-only profile

Implementation:
â€¢ Profile stored in database
â€¢ UI dropdown to switch profiles
â€¢ Each profile has isolated:
  - API keys
  - Strategy instances
  - Trading history

Future Extension:
â€¢ Easy to add multi-user later if needed
â€¢ Architecture doesn't prevent it
```

---

## Implementation Plan

### Phase 1: Foundation (Week 1-2)

**Goal**: Set up project structure and infrastructure

```
â–¡ Create uteki.open repository
â–¡ Initialize Poetry project with pyproject.toml
â–¡ Set up Docker Compose (PostgreSQL, ClickHouse, Qdrant, Redis)
â–¡ Configure Ruff + MyPy + Pre-commit hooks
â–¡ Create DDD directory structure (7 domains)
â–¡ Set up Alembic for database migrations
â–¡ Configure logging and monitoring
â–¡ Create .env.example with all configuration options
```

**Deliverables**:
- Working Docker Compose environment
- Project skeleton with DDD structure
- Development tooling configured

### Phase 2: Core Domains (Week 3-6)

**Goal**: Implement foundational domains

```
Week 3: Admin Domain
â–¡ API key management (CRUD)
â–¡ Encrypted storage (cryptography library)
â–¡ Model configuration (OpenAI, Claude, Local)
â–¡ Usage tracking and limits
â–¡ /admin frontend page

Week 4: Agent Framework
â–¡ BaseAgent abstract class
â–¡ Tool system with 10+ built-in tools
â–¡ AgentMemory with Qdrant integration
â–¡ Task execution engine
â–¡ Error handling and retries

Week 5: Trading Domain
â–¡ Exchange abstraction (OKX, Binance)
â–¡ Order placement and management
â–¡ Position tracking
â–¡ Account synchronization
â–¡ WebSocket real-time updates

Week 6: Data Domain (Part 1)
â–¡ Multi-asset data acquisition architecture (crypto, stocks, commodities)
â–¡ ClickHouse time-series storage optimization
â–¡ Real-time WebSocket data streams
â–¡ Data quality validation pipeline
```

**Deliverables**:
- Working /admin page with API key configuration
- Functional agent framework with tool system
- Trading operations (place orders, track positions)

### Phase 3: Data & Evaluation (Week 7-8)

**Goal**: Build comprehensive data pipeline and enterprise-grade evaluation

```
Week 7: Data Domain (Part 2)
â–¡ Stock market data (SP500, NASDAQ100, individual stocks)
â–¡ On-chain data collection (BTC, ETH)
â–¡ Commodity data (gold, silver, crude oil, agricultural)
â–¡ Financial report storage (PDF in MinIO, embeddings in Qdrant)
â–¡ Initial data seeding for common assets

Week 8: Evaluation Domain
â–¡ Evaluation metrics framework
â–¡ Agent performance tracking
â–¡ A/B testing system
â–¡ /evaluate frontend page
â–¡ Report generation
```

**Deliverables**:
- Comprehensive multi-asset data pipeline
- Enterprise-grade agent evaluation framework (OpenAI/Anthropic-level)
- Data quality assurance system

### Phase 4: User Experience (Week 9-10)

**Goal**: Polish UI/UX and documentation

```
Week 9: Frontend Pages
â–¡ /admin page - configuration + dashboard tabs
â–¡ /evaluate page - agent evaluation + chat interface
â–¡ Trading history visualization
â–¡ Profile switching UI

Week 10: Documentation & Onboarding
â–¡ Quick Start guide (5-min to first backtest)
â–¡ Cookbook with 10+ examples
â–¡ API documentation (auto-generated)
â–¡ Interactive tutorial on first launch
â–¡ Video walkthrough
```

**Deliverables**:
- Complete 4-page UI
- Comprehensive documentation
- Onboarding flow

### Phase 5: Data Migration & Testing (Week 11-12)

**Goal**: Migrate data and ensure quality

```
Week 11: Data Migration
â–¡ SQLite â†’ PostgreSQL migration script
â–¡ Historical data â†’ ClickHouse archival
â–¡ Generate embeddings â†’ Qdrant
â–¡ Validate data integrity

Week 12: Testing & Polish
â–¡ Unit tests (80%+ coverage)
â–¡ Integration tests for all domains
â–¡ E2E tests for critical flows
â–¡ Performance testing and optimization
â–¡ Bug fixes and polish
```

**Deliverables**:
- Automated migration scripts
- 80%+ test coverage
- Production-ready system

### Phase 6: Launch Preparation (Week 13-14)

**Goal**: Prepare for public release

```
Week 13: Deployment & CI/CD
â–¡ GitHub Actions workflows
â–¡ Automated releases
â–¡ Docker image publishing
â–¡ Installation scripts for all platforms
â–¡ Backup and restore utilities

Week 14: Final Polish & Documentation
â–¡ README with clear instructions
â–¡ CONTRIBUTING guide
â–¡ LICENSE file
â–¡ Security audit
â–¡ Performance profiling
â–¡ Beta testing with 5-10 users
```

**Deliverables**:
- Public GitHub repository
- v1.0.0 release
- Complete documentation

---

## Success Metrics

### User Experience Metrics

```
Onboarding Success:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: 90% of users complete first backtest within 15 minutes
Measure:
  - Time from `git clone` to first backtest execution
  - User drop-off at each step (setup, config, first run)

Deployment Success:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: One-command startup works on 95% of systems
Measure:
  - macOS (Intel & Apple Silicon)
  - Linux (Ubuntu, Debian, Arch)
  - Windows (WSL2)
```

### Technical Performance Metrics

```
Query Performance:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: 10x improvement over legacy system
Measure:
  - Backtest query time (100k rows): < 2s (vs 20s in SQLite)
  - Dashboard load time: < 1s
  - Strategy similarity search: < 500ms

System Reliability:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: 99.9% uptime for core services
Measure:
  - Database connection failures
  - Agent task success rate: > 95%
  - API error rate: < 1%

Code Quality:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: Professional-grade codebase
Measure:
  - Test coverage: > 80%
  - MyPy strict mode: 0 errors
  - Ruff linting: 0 violations
  - Documentation coverage: 100% of public APIs
```

### Community Metrics (Post-Launch)

```
Adoption:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: 100 GitHub stars in first month
Measure:
  - GitHub stars, forks, watchers
  - Docker Hub pulls
  - Documentation page views

Engagement:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Target: Active community forming
Measure:
  - GitHub issues/PRs
  - Discord server activity
  - Number of user-contributed strategies
```

---

## Risks & Mitigation

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Database migration data loss** | High | Low | â€¢ Automated migration scripts<br>â€¢ Comprehensive testing<br>â€¢ Backup before migration<br>â€¢ Rollback plan |
| **Performance regressions** | Medium | Medium | â€¢ Benchmark suite<br>â€¢ Performance testing in CI<br>â€¢ Profiling tools<br>â€¢ Monitor in production |
| **Docker compatibility issues** | Medium | Medium | â€¢ Test on multiple platforms<br>â€¢ Provide non-Docker alternative<br>â€¢ Detailed troubleshooting docs |
| **Agent framework complexity** | Medium | Low | â€¢ Start with simple agents<br>â€¢ Iterative development<br>â€¢ Extensive testing |
| **ClickHouse learning curve** | Low | Medium | â€¢ Provide query templates<br>â€¢ Abstract behind service layer<br>â€¢ Document common patterns |

### Project Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Scope creep** | High | Medium | â€¢ Strict Non-Goals enforcement<br>â€¢ MVP-first approach<br>â€¢ Feature freezes per phase |
| **Timeline delays** | Medium | Medium | â€¢ 2-week buffer built in<br>â€¢ Weekly progress reviews<br>â€¢ Parallel workstreams |
| **User adoption low** | Medium | Low | â€¢ Beta testing before launch<br>â€¢ Focus on documentation<br>â€¢ Active community engagement |
| **Dependency vulnerabilities** | Medium | Low | â€¢ Automated security scanning<br>â€¢ Poetry lock file<br>â€¢ Regular dependency updates |

---

## Open Questions

### Technical Questions

1. **Agent Memory Size Limits**
   - How much conversation history to store per agent?
   - Retention policy? (e.g., keep last 1000 messages)
   - Resolution: Test with different limits, measure performance impact

2. **ClickHouse Partitioning Strategy**
   - Partition by date? By symbol?
   - Retention policy for old data?
   - Resolution: Start with date partitioning (monthly), adjust based on usage

3. **LLM Rate Limiting**
   - How to handle OpenAI/Claude API rate limits?
   - Queue system? Retry logic?
   - Resolution: Implement exponential backoff + Redis queue

### Product Questions

4. **Strategy Versioning**
   - How to handle strategy updates without breaking running instances?
   - Semantic versioning for strategies?
   - Resolution: Strategy instances are immutable snapshots

5. **Data Export Format**
   - What format for strategy sharing? JSON? YAML?
   - Include backtests results in export?
   - Resolution: JSON with JSON Schema validation

6. **Profile Switching Behavior**
   - What happens to running strategies when switching profiles?
   - Auto-pause? Warning?
   - Resolution: Warn user, require explicit stop before switch

### Community Questions

7. **License Choice**
   - MIT (permissive) vs AGPL (copyleft)?
   - Commercial use allowed?
   - Resolution: MIT for maximum adoption

8. **Contribution Guidelines**
   - How to accept community strategies?
   - Code review process?
   - Resolution: Define CONTRIBUTING.md with clear standards

---

## Appendix

### A. Technology Evaluation Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category        â”‚ Option 1 â”‚ Option 2 â”‚ Option 3 â”‚ Selected â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dependency Mgmt â”‚ Poetry   â”‚ PDM      â”‚ uv       â”‚ Poetry   â”‚
â”‚ Primary DB      â”‚ SQLite   â”‚ Postgres â”‚ MySQL    â”‚ Postgres â”‚
â”‚ Analytics DB    â”‚ Postgres â”‚ ClickH.  â”‚ DuckDB   â”‚ ClickH.  â”‚
â”‚ Vector DB       â”‚ Qdrant   â”‚ Chroma   â”‚ Milvus   â”‚ Qdrant   â”‚
â”‚ Cache           â”‚ Redis    â”‚ Memcache â”‚ None     â”‚ Redis    â”‚
â”‚ Linter          â”‚ Ruff     â”‚ Black    â”‚ Pylint   â”‚ Ruff     â”‚
â”‚ Type Checker    â”‚ MyPy     â”‚ Pyright  â”‚ None     â”‚ MyPy     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### B. Directory Structure Reference

See [Technical Architecture](#technical-architecture) section for complete directory tree.

### C. Migration Scripts

```python
# Example: SQLite to PostgreSQL migration
# Location: scripts/migrate_sqlite_to_pg.py

import asyncio
from sqlalchemy import create_engine
from backend.models import all_models

async def migrate():
    # 1. Connect to both databases
    sqlite_engine = create_engine("sqlite:///data/old.db")
    pg_engine = create_engine("postgresql://...")

    # 2. Create tables in PostgreSQL
    Base.metadata.create_all(pg_engine)

    # 3. Copy data table by table
    for model in all_models:
        print(f"Migrating {model.__tablename__}...")
        # Batch copy with progress bar
        ...

    print("âœ“ Migration complete!")

if __name__ == "__main__":
    asyncio.run(migrate())
```

### D. Configuration Template

See `.env.example` in project root for complete configuration template.

---

## Approval & Next Steps

### Stakeholder Sign-Off

- [ ] Technical Architect - _Pending_
- [ ] Product Owner - _Pending_
- [ ] Community Lead - _Pending_

### Next Artifacts (OpenSpec Workflow)

1. **Design Document** (`design.md`)
   - Detailed API specifications
   - Database schema designs
   - Agent framework class diagrams
   - UI/UX mockups

2. **Technical Specification** (`specs/`)
   - Per-domain specifications
   - API contracts
   - Data models

3. **Task Breakdown** (`tasks.md`)
   - Detailed implementation tasks
   - Dependencies between tasks
   - Time estimates

### Questions for Stakeholders

1. Do you agree with the single-user + profile approach? Or should we prioritize multi-user from day 1?
2. Is the 14-week timeline acceptable? Should we cut scope for faster MVP?
3. Any critical features missing from the proposal?

---

**End of Proposal**

_This proposal will evolve based on feedback. Please submit comments via GitHub Issues._
